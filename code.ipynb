{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7PCPFrNAleF"
      },
      "source": [
        "## Broad Outline\n",
        "\n",
        "In this assignment, we will implement different types of language models for modeling Indian names. There are clealry patterns in Indian names that models could learn, and we start modeling those using n-gram models, then move to neural n-gram and RNN models.\n",
        "\n",
        "\n",
        "**Marks Distribution:**\n",
        "- Unigram: 5\n",
        "- Bigram: 15\n",
        "- Trigram: 10\n",
        "- Neural N-gram LM: 30\n",
        "- RNN LM: 40\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRfBYfGr_Brg"
      },
      "source": [
        "# Read and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwZ5kF6r_ER2"
      },
      "outputs": [],
      "source": [
        "# importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import random\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuKwSZRvktVK"
      },
      "source": [
        "Please note that we may change the contents of the following four files when we rerun your code, so please make sure that your solution is not specifically engineered to just these names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZlaqugU_EPv",
        "outputId": "58093fb1-2808-4685-a6f1-a559fd6cfe3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-25 10:29:39--  https://docs.google.com/spreadsheets/d/1AUzwOQQbAehg_eoAMCcWfwSGhKwSAtnIzapt2wbv0Zs/gviz/tq?tqx=out:csv&sheet=train_data.csv\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.206.138, 173.194.206.100, 173.194.206.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.206.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘train_data.csv’\n",
            "\n",
            "\rtrain_data.csv          [<=>                 ]       0  --.-KB/s               \rtrain_data.csv          [ <=>                ]  71.07K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2024-02-25 10:29:39 (4.98 MB/s) - ‘train_data.csv’ saved [72776]\n",
            "\n",
            "--2024-02-25 10:29:39--  https://docs.google.com/spreadsheets/d/1UtQErvMS-vcQEwjZIjLFnDXlRZPxgO1CU3PF-JYQKvA/gviz/tq?tqx=out:csv&sheet=valid_data.csv\n",
            "Resolving docs.google.com (docs.google.com)... 173.194.206.138, 173.194.206.100, 173.194.206.139, ...\n",
            "Connecting to docs.google.com (docs.google.com)|173.194.206.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘valid_data.csv’\n",
            "\n",
            "valid_data.csv          [ <=>                ]  19.76K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-25 10:29:39 (100 MB/s) - ‘valid_data.csv’ saved [20230]\n",
            "\n",
            "--2024-02-25 10:29:40--  https://drive.google.com/uc?export=download&id=1tuRLJXLd2VcDaWENr8JTZMcjFlwyRo60\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.198.102, 173.194.198.100, 173.194.198.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.198.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1tuRLJXLd2VcDaWENr8JTZMcjFlwyRo60&export=download [following]\n",
            "--2024-02-25 10:29:40--  https://drive.usercontent.google.com/download?id=1tuRLJXLd2VcDaWENr8JTZMcjFlwyRo60&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.201.132, 2607:f8b0:4001:c01::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.201.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12 [application/octet-stream]\n",
            "Saving to: ‘eval_prefixes.txt’\n",
            "\n",
            "eval_prefixes.txt   100%[===================>]      12  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-25 10:29:40 (662 KB/s) - ‘eval_prefixes.txt’ saved [12/12]\n",
            "\n",
            "--2024-02-25 10:29:40--  https://drive.google.com/uc?export=download&id=1kjPAR04UTKmdtV-FJ9SmDlotkt-IKM3b\n",
            "Resolving drive.google.com (drive.google.com)... 173.194.198.102, 173.194.198.100, 173.194.198.139, ...\n",
            "Connecting to drive.google.com (drive.google.com)|173.194.198.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1kjPAR04UTKmdtV-FJ9SmDlotkt-IKM3b&export=download [following]\n",
            "--2024-02-25 10:29:40--  https://drive.usercontent.google.com/download?id=1kjPAR04UTKmdtV-FJ9SmDlotkt-IKM3b&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 74.125.201.132, 2607:f8b0:4001:c01::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|74.125.201.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12 [application/octet-stream]\n",
            "Saving to: ‘eval_sequences.txt’\n",
            "\n",
            "eval_sequences.txt  100%[===================>]      12  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-25 10:29:40 (580 KB/s) - ‘eval_sequences.txt’ saved [12/12]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the training and validation datasets\n",
        "!wget -O train_data.csv \"https://docs.google.com/spreadsheets/d/1AUzwOQQbAehg_eoAMCcWfwSGhKwSAtnIzapt2wbv0Zs/gviz/tq?tqx=out:csv&sheet=train_data.csv\"\n",
        "!wget -O valid_data.csv \"https://docs.google.com/spreadsheets/d/1UtQErvMS-vcQEwjZIjLFnDXlRZPxgO1CU3PF-JYQKvA/gviz/tq?tqx=out:csv&sheet=valid_data.csv\"\n",
        "\n",
        "# Download the text for evaluation\n",
        "!wget -O eval_prefixes.txt \"https://drive.google.com/uc?export=download&id=1tuRLJXLd2VcDaWENr8JTZMcjFlwyRo60\"\n",
        "!wget -O eval_sequences.txt \"https://drive.google.com/uc?export=download&id=1kjPAR04UTKmdtV-FJ9SmDlotkt-IKM3b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xv2bBmxbGlR2",
        "outputId": "70995295-864b-4acd-f514-99cfd52e94e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of training data: 4539\n",
            "Length of validation data: 1297\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "def read_dataframe(ds_type):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        ds_type [str] :  dataset type (train or valid)\n",
        "\n",
        "    Returns:\n",
        "        df [pandas dataframe]\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_csv(f\"/content/{ds_type}_data.csv\", header=0, index_col=0)\n",
        "    df = df[~df['Name'].isna()]\n",
        "    df['Name'] = df['Name'].astype(str)\n",
        "    return df\n",
        "\n",
        "# Load the training and validation datasets\n",
        "train_data = read_dataframe(\"train\")\n",
        "validation_data = read_dataframe(\"valid\")\n",
        "\n",
        "# Read files containing prefixes and character sequences for evaluation\n",
        "with open('eval_prefixes.txt', 'r') as file:\n",
        "    eval_prefixes = []\n",
        "    for line in file:\n",
        "        eval_prefixes.append(line.strip().split(\" \"))\n",
        "\n",
        "with open('eval_sequences.txt', 'r') as file:\n",
        "    eval_sequences = []\n",
        "    for line in file:\n",
        "        eval_sequences.append(line.strip().split(\" \"))\n",
        "\n",
        "print(f\"Length of training data: {len(train_data)}\\nLength of validation data: {len(validation_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjAkd4OKHQDr"
      },
      "outputs": [],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "START = \"<s>\"   # Start-of-name token\n",
        "END = \"</s>\"    # End-of-name token\n",
        "UNK = \"<unk>\"   # token representing out of unknown (or out of vocabulary) tokens\n",
        "vocab_from_ascii = True\n",
        "\n",
        "def build_vocab(names):\n",
        "    \"\"\"\n",
        "    Builds a vocabulary given a list of names\n",
        "\n",
        "    Args:\n",
        "        names [list[str]]: list of names\n",
        "\n",
        "    Returns:\n",
        "        vocab [torchtext.vocab]: vocabulary based on the names\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if vocab_from_ascii:\n",
        "        char_counts = {chr(i):i for i in range(128)}\n",
        "    else:\n",
        "        char_counts = Counter(\"\".join(names))\n",
        "\n",
        "    vocab = build_vocab_from_iterator(\n",
        "                    char_counts,\n",
        "                    specials=[UNK, START, END], #adding special tokens to the vocabulary\n",
        "                    min_freq=1\n",
        "                )\n",
        "    vocab.set_default_index(vocab[UNK])\n",
        "    return vocab\n",
        "\n",
        "\n",
        "def tokenize_name(name):\n",
        "    \"\"\"\n",
        "    Tokenise the name i.e. break a name into list of characters\n",
        "\n",
        "    Args:\n",
        "        name [str]: name to be tokenized\n",
        "\n",
        "    Returns:\n",
        "        list of characters\n",
        "    \"\"\"\n",
        "\n",
        "    return list(str(name))\n",
        "\n",
        "\n",
        "def process_data_for_input(data_iter, vocab):\n",
        "    \"\"\"\n",
        "    Processes data for input: Breaks names into characters,\n",
        "    converts out of vocabulary tokens to UNK and\n",
        "    appends END token at the end of every name\n",
        "\n",
        "    Args:\n",
        "        data_iter: data iterator consisting of names\n",
        "        vocab: vocabulary\n",
        "\n",
        "    Returns:\n",
        "        data_iter [list[list[str]]]: list of names, where each name is a\n",
        "                                list of characters and is appended with\n",
        "                                START and END tokens\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_set = set(vocab.get_itos())\n",
        "    # convert Out Of Vocabulary (OOV) tokens to UNK tokens\n",
        "    data_iter = [[char if char in vocab_set else UNK\n",
        "                        for char in tokenize_name(name)] for name in data_iter]\n",
        "    data_iter = [[START] + name + [END] for name in data_iter]\n",
        "\n",
        "    return data_iter\n",
        "\n",
        "\n",
        "def get_tokenised_text_and_vocab(ds_type, vocab=None):\n",
        "    \"\"\"\n",
        "    Reads input data, tokenizes it, builds vocabulary (if unspecified)\n",
        "    and outputs tokenised list of names (which in turn is a list of characters)\n",
        "\n",
        "    Args:\n",
        "        ds_type [str]: Type of the dataset (e.g., train, validation, test)\n",
        "        vocab [torchtext.vocab]: vocabulary;\n",
        "                                 If vocab is None, the function will\n",
        "                                 build the vocabulary from input text.\n",
        "                                 If vocab is provided, it will tokenize name\n",
        "                                 according to the vocab, replacing any tokens\n",
        "                                 not part of the vocab with UNK token.\n",
        "\n",
        "    Returns:\n",
        "        data_iter: data iterator for tokenized names\n",
        "        vocab: vocabulary\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # read the 'Name' column of the dataframe\n",
        "    if ds_type=='train':\n",
        "        data_iter = train_data['Name']\n",
        "    elif ds_type=='valid':\n",
        "        data_iter = validation_data['Name']\n",
        "    else:\n",
        "        data_iter = test_data['Name']\n",
        "\n",
        "    # build vocab from input data, if vocab is unspecified\n",
        "    if vocab is None:\n",
        "        vocab = build_vocab(data_iter)\n",
        "\n",
        "    # convert OOV chars to UNK, append START and END token to each name\n",
        "    data_iter = process_data_for_input(data_iter, vocab)\n",
        "\n",
        "    return data_iter, vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZOCgikIKQMT"
      },
      "source": [
        "Let's look at some examples from the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zs1WLnSwKL7o",
        "outputId": "1719db38-81ab-481e-ed69-d158654a3cb9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Examples from the training set: firtu, japneet, bhhatu, asman, ashman'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at some random examples from the training set\n",
        "examples = \", \".join(random.sample(list(train_data['Name']), 5))\n",
        "f\"Examples from the training set: {examples}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ao45NGBZoGt6"
      },
      "source": [
        "# Module 1: N-gram Language Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y1aGXxaSKK7"
      },
      "source": [
        "Load and preprocess the data for n-gram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja95kukk5Tjb"
      },
      "outputs": [],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "MAX_NAME_LENGTH = 8 # maximum length of names for generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YUgIT0uH9Jp",
        "outputId": "2f58d4bc-fb81-4f89-9ea2-ccb787f20522"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131\n"
          ]
        }
      ],
      "source": [
        "# Get data iterator and build vocabulary from input text\n",
        "\n",
        "train_text, vocab = get_tokenised_text_and_vocab(ds_type='train')\n",
        "validation_text, _ = get_tokenised_text_and_vocab(ds_type='valid', vocab=vocab)\n",
        "\n",
        "# Check the size of vocabulary\n",
        "vocab_size = len(vocab.get_stoi())\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtpfw2ZCfrFf"
      },
      "source": [
        "\n",
        "Now it's time to implement an [n-gram language model](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "One edge case you will need to handle is that you don't have $n-1$ prior characters at the beginning of the text.  One way to do this is by appending the `START` token $n-1$ times at the start of the name, when implementing an $n$-gram model. You may choose whichever method you like to handle this case as long as you produce a valid probability distribution (one that sums to one).\n",
        "\n",
        "**Generating names**\n",
        "\n",
        "To generate from a language model, we can sample one char at a time conditioning on the chars we have generated so far.\n",
        "\n",
        "In fact there are many strategies to get better-sounding samples, such as only sampling from the top-k chars or sharpening the distribution with a temperature.  You can read more about sampling from a language model in [this](https://arxiv.org/pdf/1904.09751.pdf) paper.\n",
        "\n",
        "\n",
        "We will now implement N-gram models with $N=1$ (unigram), $N=2$ (bigram), and $N=3$ (trigram).\n",
        "\n",
        "**Utility Functions**\n",
        "\n",
        "Implement the utility functions `get_unigram_counts`, `get_bigram_counts` and `get_trigram_counts`. You can use these functions while implementing n-gram models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG5lMSVDfoyX"
      },
      "outputs": [],
      "source": [
        "def get_unigram_counts(corpus):\n",
        "    \"\"\"\n",
        "    Given a corpus, calculates the unigram counts for each character in the corpus\n",
        "\n",
        "    Args:\n",
        "        corpus [list[list[str]]]: list of tokenized characters. Text is appended with END token.\n",
        "\n",
        "    Returns:\n",
        "        unigram_counts [dict [key: char, value: count]]:\n",
        "            dictionary of unigram counts for each character in the corpus\n",
        "        Example:\n",
        "        > unigram_counts[\"c1\"] = 5\n",
        "    \"\"\"\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "\n",
        "    unigram_counts = dict(Counter([char for name in corpus for char in name]))\n",
        "\n",
        "    # # taking only alphanumeric characters\n",
        "    # unigram_counts = {k: v for k, v in unigram_counts.items() if k.isalpha()}\n",
        "\n",
        "    return unigram_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YhWT1YdgY3P"
      },
      "outputs": [],
      "source": [
        "def get_bigram_counts(corpus):\n",
        "    \"\"\"\n",
        "    Given a corpus, calculates the bigram counts for each bigram in the corpus.\n",
        "    The corpus *only* contains END tokens at the end of names.\n",
        "    You may want to handle the case whhere beginning of the name\n",
        "    does not have n-1 prior chars.\n",
        "\n",
        "    Args:\n",
        "        corpus [list[list[str]]]: list of tokenized text. Text is appended with END token.\n",
        "\n",
        "    Returns:\n",
        "        bigram_counts [dict[dict]]:\n",
        "            nested dictionary of bigram counts for each bigram in the corpus\n",
        "        Example:\n",
        "        > bigram_counts[\"c1\"][\"c2\"] = 5\n",
        "        here bigram_counts[\"c1\"][\"c2\"] represents P(\"c2\"|\"c1\")\n",
        "        P[\"c1\"][\"c2\"] means P[char_i = \"c2\"|char_{i-1} = \"c1\"]\n",
        "    \"\"\"\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    bigram_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "    for name in corpus:\n",
        "        for i in range(len(name)-1):\n",
        "            # if name[i].isalpha() and name[i+1].isalpha():\n",
        "            bigram_counts[name[i]][name[i+1]] += 1\n",
        "\n",
        "    return bigram_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZefWM6x2CSH"
      },
      "outputs": [],
      "source": [
        "def get_trigram_counts(corpus):\n",
        "    \"\"\"\n",
        "    Given a corpus, calculates the trigram counts for each trigram in the corpus.\n",
        "    The corpus *only* contains END tokens at the end of names.\n",
        "    You may want to handle the case where beginning of the text\n",
        "    does not have n-1 prior chars.\n",
        "\n",
        "    Args:\n",
        "        corpus [list[list[str]]]: list of tokenized text. Text is appended with END token.\n",
        "\n",
        "    Returns:\n",
        "        trigram_counts [dict[dict[dict]]]:\n",
        "            nested dictionary for each trigram in the corpus\n",
        "        Example:\n",
        "        > trigram_counts[\"c1\"][\"c2\"][\"c3\"] = 5\n",
        "        P[\"c1\"][\"c2\"][\"c3] means P[char_i = \"c3\"|char_{i-2} = \"c1\", char_{i-1} = \"c2\"]\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "    trigram_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "    for name in corpus:\n",
        "        for i in range(len(name)-2):\n",
        "            #if name[i].isalpha() and name[i+1].isalpha() and name[i+2].isalpha():\n",
        "            trigram_counts[name[i]][name[i+1]][name[i+2]] += 1\n",
        "\n",
        "    return trigram_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzrZT7KdWvyh"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of the n-gram language models.\n",
        "All other n-gram models (unigram, bigram, etc.) would follow the same skeleton.\n",
        "\"\"\"\n",
        "\n",
        "class NGramLanguageModel(object):\n",
        "    def __init__(self, train_text):\n",
        "        \"\"\"\n",
        "        Initialise and train the model with train_text.\n",
        "\n",
        "        Args:\n",
        "            train_text [list of list]: list of tokenised names\n",
        "\n",
        "        Returns:\n",
        "            -\n",
        "        \"\"\"\n",
        "        return\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Returns a probability distribution over all chars in the vocabulary.\n",
        "        Probability distribution should sum to one.\n",
        "\n",
        "        Returns:\n",
        "            P: dictionary or nested dictionary; Output format depends on n-gram\n",
        "            Examples:\n",
        "                for N=1 (unigram); dict[key:unigram,value:probability of unigram]\n",
        "                    > P[\"c1\"] = 0.0001\n",
        "                for N=2 (bigram); dict[key:bigram_char1, value:dict[key:bigram_char2,value:probability of bigram]]\n",
        "                    > P[\"c1\"][\"c2\"] = 0.0001\n",
        "                    P[\"c1\"][\"c2\"] means P[\"c2\"|\"c1\"]\n",
        "                for N=3 (trigram); dict[dict[dict]]\n",
        "                    > P[\"c1\"][\"c2\"][\"c3\"] = 0.0001\n",
        "                    P[\"c1\"][\"c2\"][\"c3] means P[char_i = \"c3\"|char_{i-2} = \"c1\", char_{i-1} = \"c2\"]\n",
        "        \"\"\"\n",
        "\n",
        "        return\n",
        "\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the language model\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            log_prob [float]: Log probability of the given name\n",
        "        \"\"\"\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on a text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list]: a list of string tokens\n",
        "\n",
        "        Returns:\n",
        "            perplexity [float]: perplexity of the given text\n",
        "        \"\"\"\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n=MAX_NAME_LENGTH, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "        You may stop the generation when n tokens have been generated,\n",
        "        or when you encounter the END token.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            names [list[str]]: list of generated names\n",
        "        \"\"\"\n",
        "        return []\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brl9eamN5aql"
      },
      "outputs": [],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "def check_validity(model, ngram, is_neural):\n",
        "    \"\"\"\n",
        "    Checks if get_next_char_probabilities returns a valid probability distribution\n",
        "    \"\"\"\n",
        "\n",
        "    if ngram==1 or is_neural:\n",
        "        P = model.get_next_char_probabilities()\n",
        "        is_valid = validate_probability_distribution(P.values())\n",
        "        if not is_valid:\n",
        "            return is_valid\n",
        "\n",
        "    elif ngram==2:\n",
        "        P = model.get_next_char_probabilities()\n",
        "        for char1 in P.keys():\n",
        "            is_valid = validate_probability_distribution(list(P[char1].values()))\n",
        "            if not is_valid:\n",
        "                return is_valid\n",
        "\n",
        "    elif ngram==3:\n",
        "        P = model.get_next_char_probabilities()\n",
        "        for char1 in P.keys():\n",
        "            for char2 in P[char1].keys():\n",
        "                is_valid = validate_probability_distribution(list(P[char1][char2].values()))\n",
        "                if not is_valid:\n",
        "                    return is_valid\n",
        "    else:\n",
        "        print(\"Enter a valid number for ngram\")\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def validate_probability_distribution(probs):\n",
        "    \"\"\"\n",
        "    Checks if probs is a valid probability distribution\n",
        "    \"\"\"\n",
        "    if not min(probs) >= 0:\n",
        "        print(\"Negative value in probabilities\")\n",
        "        return False\n",
        "    elif not max(probs) <= 1 + 1e-8:\n",
        "        print(\"Value larger than 1 in probabilities\")\n",
        "        return False\n",
        "    elif not abs(sum(probs)-1) < 1e-4:\n",
        "        print(\"probabilities do not sum to 1\")\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def eval_ngram_model(model, ngram, ds, ds_name, eval_prefixes, eval_sequences, num_names=5, is_neural=False):\n",
        "    \"\"\"\n",
        "    Runs the following evaluations on n-gram models:\n",
        "    (1) checks if probability distribution returned by model.get_next_char_probabilities() sums to one\n",
        "    (2) checks the perplexity of the model\n",
        "    (3) generates names using model.generate_names()\n",
        "    (4) generates names given a prefix using model.generate_names()\n",
        "    (4) output most likely characters after a given sequence of chars using model.get_most_likely_chars()\n",
        "    \"\"\"\n",
        "\n",
        "    # (1) checks if probability distributions sum to one\n",
        "    is_valid = check_validity(model=model, ngram=ngram, is_neural=is_neural)\n",
        "\n",
        "    print(f'EVALUATION probability distribution is valid: {is_valid}')\n",
        "\n",
        "    # (2) evaluate the perplexity of the model on the dataset\n",
        "    print(f'EVALUATION of {ngram}-gram on {ds_name} perplexity:',\n",
        "        model.get_perplexity(ds))\n",
        "\n",
        "    # (3) generate a few names\n",
        "    generated_names = \", \".join(model.generate_names(k=num_names))\n",
        "    print(f'EVALUATION {ngram}-gram generated names are {generated_names}')\n",
        "\n",
        "    # (4) generate a few names given a prefix\n",
        "    for prefix in eval_prefixes:\n",
        "        generated_names_with_prefix = \", \".join(model.generate_names(k=num_names, prefix=prefix))\n",
        "        prefix = ''.join(prefix)\n",
        "        print(f'EVALUATION {ngram}-gram generated names with prefix {prefix} are {generated_names_with_prefix}')\n",
        "\n",
        "    # (5) get most likely characters after a sequence\n",
        "    for sequence in eval_sequences:\n",
        "        most_likely_chars = \", \".join(model.get_most_likely_chars(sequence=sequence, k=num_names))\n",
        "        sequence = \"\".join(sequence)\n",
        "        print(f\"EVALUATION {ngram}-gram top most likely chars after {sequence} are {most_likely_chars}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIePKuk-eGQm"
      },
      "source": [
        "## 1.1 Unigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9s9IXffIMmaa"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementaion of a Unigram Model without smoothing\n",
        "\"\"\"\n",
        "\n",
        "class UnigramModel(NGramLanguageModel):\n",
        "    def __init__(self, train_text):\n",
        "        \"\"\"\n",
        "        Initialise and train the model with train_text.\n",
        "\n",
        "        Args:\n",
        "            train_text [list of list]: list of tokenised names\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Initialise the train_text\n",
        "        super().__init__(train_text)\n",
        "        self.train_text = train_text\n",
        "        self.unigram_counts = get_unigram_counts(self.train_text)\n",
        "\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Return a dictionary of probabilities for each char in the vocabulary\n",
        "\n",
        "        Returns:\n",
        "            key: char, value: probability\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # unigram_counts = get_unigram_counts([self.train_text])\n",
        "        unigram_total = sum(self.unigram_counts.values())\n",
        "        next_char_probabilities = {char: count/unigram_total for char, count in self.unigram_counts.items()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Get the probabilities of each character if it is in the vocabulary and 0 if it is not\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[char]) if char in next_char_probabilities else np.log(0) for char in name])\n",
        "\n",
        "        #name_log_probability = sum([np.log(self.get_next_char_probabilities()[char]) for char in name])\n",
        "\n",
        "        return name_log_probability\n",
        "\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on a text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list]: a list of string tokens\n",
        "\n",
        "        Returns:\n",
        "            perplexity of the given text [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for name in self.train_text:\n",
        "            count = count + len(name)\n",
        "\n",
        "        perplexity = np.exp(-sum([self.get_name_log_probability(name) for name in text])/count)\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n=MAX_NAME_LENGTH, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            list of generated names [list]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        names = []\n",
        "        for _ in range(k):\n",
        "            name = [START]\n",
        "            while name[-1] != END and len(name) < n:\n",
        "                next_char = np.random.choice(list(self.get_next_char_probabilities().keys()), p=list(self.get_next_char_probabilities().values()))\n",
        "                if next_char != '<s>' and next_char != '</s>':\n",
        "                    name.append(next_char)\n",
        "            names.append(\"\".join(name[1:]))\n",
        "\n",
        "        return names\n",
        "\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        most_likely_chars = sorted(next_char_probabilities, key=next_char_probabilities.get, reverse=True)[:k]\n",
        "\n",
        "        return most_likely_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPcVNCYDfwFz"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBPe6h00gJlr"
      },
      "source": [
        "**Note**: For models without smoothing, you may observe perplexity as `inf` if the validation or test set contains characters not seen in the train set\n",
        "However, this should not happen for models where you implement smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQYB_iVW7PWQ",
        "outputId": "27299523-ae1b-4f8e-c633-2504a3f06bbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unigram train perplexity: 16.623900007096303\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "unigram_model = UnigramModel(train_text)\n",
        "\n",
        "# Check the perplexity of the unigram model on the train set\n",
        "print('unigram train perplexity:',\n",
        "      unigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwZDmVL77j5b",
        "outputId": "867375a8-66f8-467e-db1e-6330b24cc134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 1-gram on validation perplexity: inf\n",
            "EVALUATION 1-gram generated names are aseeaen, rmmmanr, yalmns&, ujcihna, kneiiar\n",
            "EVALUATION 1-gram generated names with prefix <s><s>sh are aiarlnd, aatahrr, nhdrmyn, oaulahn, uauipti\n",
            "EVALUATION 1-gram top most likely chars after <s><s>aa are a, <s>, </s>, i, n\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-af1115804725>:55: RuntimeWarning: divide by zero encountered in log\n",
            "  name_log_probability = sum([np.log(next_char_probabilities[char]) if char in next_char_probabilities else np.log(0) for char in name])\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=unigram_model, ngram=1, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64KYOJh2hCHS"
      },
      "source": [
        "### Smoothing\n",
        "\n",
        "Implement a smoothed version of the unigram model. You may extend the `UnigramModel` class and re-use some of the functions.  For unigram model, you should implement Add-1 smoothing.\n",
        "\n",
        "You may refer to the lecture slides or [3.5 Smoothing](https://web.stanford.edu/~jurafsky/slp3/3.pdf) for details on different smoothing technqiues.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eefDQsXyWipv"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of unigram model with Add-1 smoothing.\n",
        "\n",
        "\"\"\"\n",
        "class SmoothedUnigramModel(UnigramModel):\n",
        "\n",
        "    def __init__(self, train_text):\n",
        "        super().__init__(train_text)\n",
        "\n",
        "    # You should override ONLY those functions\n",
        "    # which calculate probability of a unigram.\n",
        "    # You can override get_next_char_probabilities\n",
        "    # or any other helper functions you use in UnigramModel\n",
        "    # to calculate unigram probabilities.\n",
        "\n",
        "    # Implement Laplace or Add-1 smoothing for the unigram model\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Return a dictionary of probabilities for each char in the vocabulary\n",
        "        with Add-1 smoothing\n",
        "\n",
        "        Returns:\n",
        "            key: char, value: probability\n",
        "        \"\"\"\n",
        "\n",
        "        unigram_total = sum(self.unigram_counts.values())\n",
        "        next_char_probabilities = {char: (count+1)/(unigram_total+len(vocab)) for char, count in self.unigram_counts.items()}\n",
        "        next_char_probabilities['<unk>'] = 1/(unigram_total+len(vocab))\n",
        "        next_char_probabilities = {char: prob/sum(next_char_probabilities.values()) for char, prob in next_char_probabilities.items()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Get the probabilities of each character if it is in the vocabulary and 0 if it is not\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[char]) if char in next_char_probabilities else np.log(next_char_probabilities['<unk>']) for char in name])\n",
        "\n",
        "        #name_log_probability = sum([np.log(self.get_next_char_probabilities()[char]) for char in name])\n",
        "\n",
        "        return name_log_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISM9uM2H8K7O",
        "outputId": "9fb62c6a-be5c-4efa-8928-7dc9ce11339c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "smoothed unigram train perplexity: 16.62510142141067\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "smoothed_unigram_model = SmoothedUnigramModel(train_text)\n",
        "\n",
        "# Check the perplexity of the smoothed unigram model on the train set\n",
        "print('smoothed unigram train perplexity:',\n",
        "      smoothed_unigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuawSvP58K7P",
        "outputId": "44904c83-5769-42be-9567-f7fb028e510e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 1-gram on validation perplexity: 2.5691810370234953\n",
            "EVALUATION 1-gram generated names are lmsrhum, tyclalj, ylaiulr, hnscdmm, dbpafyd\n",
            "EVALUATION 1-gram generated names with prefix <s><s>sh are ahirera, nasyana, jluetdm, lpisbip, najriae\n",
            "EVALUATION 1-gram top most likely chars after <s><s>aa are a, <s>, </s>, i, n\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=smoothed_unigram_model, ngram=1, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences,  num_names=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYdm3Ox09g96"
      },
      "outputs": [],
      "source": [
        "# Release models we don't need any more.\n",
        "del unigram_model\n",
        "del smoothed_unigram_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZOZ_XnseIXP"
      },
      "source": [
        "## 1.2 Bigram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwJflAiVaM36"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of a Bigram Model.\n",
        "\"\"\"\n",
        "\n",
        "class BigramModel(NGramLanguageModel):\n",
        "    def __init__(self, train_text):\n",
        "        \"\"\"\n",
        "        Initialise and train the model with train_text.\n",
        "\n",
        "        Args:\n",
        "            train_text [list of list]: list of tokenised names\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Initialise the train_text\n",
        "        super().__init__(train_text)\n",
        "        self.bigram_counts = get_bigram_counts(train_text)\n",
        "        self.train_text = train_text\n",
        "\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Returns a probability distribution over all chars in the vocabulary.\n",
        "        Probability distribution should sum to one.\n",
        "\n",
        "        Returns:\n",
        "            P: dictionary or nested dictionary; Output format depends on n-gram\n",
        "            Examples:\n",
        "                for N=2 (bigram); dict[key:bigram_char1, value:dict[key:bigram_char2,value:probability of bigram]]\n",
        "                    > P[\"a\"][\"b\"] = 0.0001 (which stands of P(\"b\"|\"a\"))\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        bigram_total = {char1: sum(self.bigram_counts[char1].values()) for char1 in self.bigram_counts.keys()}\n",
        "        next_char_probabilities = {char1: {char2: count/bigram_total[char1] for char2, count in self.bigram_counts[char1].items()} for char1 in self.bigram_counts.keys()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model.\n",
        "        Be careful with cases for which probability of the name is zero.\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[name[i-1]][name[i]]) if name[i-1] in next_char_probabilities and name[i] in next_char_probabilities[name[i-1]] else np.log(0) for i in range(1, len(name))])\n",
        "\n",
        "        return name_log_probability\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on a text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list]: a list of string tokens\n",
        "\n",
        "        Returns:\n",
        "            perplexity of the given text [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for name in self.train_text:\n",
        "            count = count + len(name)\n",
        "\n",
        "        perplexity = np.exp(-sum([self.get_name_log_probability(name) for name in text])/count)\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n=MAX_NAME_LENGTH, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            list of generated names [list]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        names = []\n",
        "        for _ in range(k):\n",
        "            name = [START] if prefix is None else prefix.copy()\n",
        "            while name[-1] != END and len(name) < n:\n",
        "                next_char = np.random.choice(list(self.get_next_char_probabilities()[name[-1]].keys()), p=list(self.get_next_char_probabilities()[name[-1]].values()))\n",
        "                if next_char != '<s>' and next_char != '</s>':\n",
        "                    name.append(next_char)\n",
        "            if prefix is None:\n",
        "                names.append(\"\".join(name[1:]))\n",
        "            else:\n",
        "                names.append(\"\".join(name[0:]))\n",
        "\n",
        "        return names\n",
        "\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        most_likely_chars = sorted(next_char_probabilities[sequence[-1]], key=next_char_probabilities[sequence[-1]].get, reverse=True)[:k]\n",
        "\n",
        "        return most_likely_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUIOOq0DjR2A"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FH3ETGRIcinT",
        "outputId": "00eb1c15-1d6a-4ea1-e827-dcf1f3d51374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bigram train perplexity: 7.658283554851139\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "bigram_model = BigramModel(train_text)\n",
        "\n",
        "# check the perplexity of the bigram model on training data\n",
        "print('bigram train perplexity:',\n",
        "      bigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BN8phEn8i0k",
        "outputId": "5c7f1062-be4b-451f-c8fd-04d4e5d16c65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-06418783bd74>:57: RuntimeWarning: divide by zero encountered in log\n",
            "  name_log_probability = sum([np.log(next_char_probabilities[name[i-1]][name[i]]) if name[i-1] in next_char_probabilities and name[i] in next_char_probabilities[name[i-1]] else np.log(0) for i in range(1, len(name))])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION of 2-gram on validation perplexity: inf\n",
            "EVALUATION 2-gram generated names are shayaum, aluemam, ralikha, argeeta, akafana\n",
            "EVALUATION 2-gram generated names with prefix <s><s>sh are <s><s>shakas, <s><s>shinac, <s><s>shaaja, <s><s>shekoo, <s><s>shalal\n",
            "EVALUATION 2-gram top most likely chars after <s><s>aa are </s>, n, r, m, l\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=bigram_model, ngram=2, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLmvdpBohH6G"
      },
      "source": [
        "### Smoothing\n",
        "\n",
        "Implement a smoothed version of the bigram model. You may extend the `BigramModel` class and re-use some of the functions.\n",
        "\n",
        "You will implement the following smoothing techniques:\n",
        "-  Laplace or add-k smoothing\n",
        "- Interpolation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kj-gNsX08jC"
      },
      "source": [
        "**Laplace or Add-k smoothing**\n",
        "- what is the effect of changing `k`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s22-fpeT4bgU"
      },
      "outputs": [],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please feel free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated names and perplexity\n",
        "\n",
        "BIGRAM_LAPLACE_K = 1 # value of k for add-k or Laplac smoothing in bigram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHsod0DXfEx8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of a bigram model with laplace or add-k smoothing.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "class LaplaceSmoothedBigramModel(BigramModel):\n",
        "    # This class extends BigramModel.\n",
        "\n",
        "    def __init__(self, train_text, k):\n",
        "        super().__init__(train_text)\n",
        "        self.k = k # specify k for smoothing\n",
        "\n",
        "    # You should override ONLY those functions\n",
        "    # which calculate probability of a bigram.\n",
        "    # You can override get_next_char_probabilities\n",
        "    # or any other helper functions you use in BigramModel\n",
        "    # to calculate bigram probabilities.\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Returns a probability distribution over all chars in the vocabulary.\n",
        "        Probability distribution should sum to one.\n",
        "\n",
        "        Returns:\n",
        "            P: dictionary or nested dictionary; Output format depends on n-gram\n",
        "            Examples:\n",
        "                for N=2 (bigram); dict[key:bigram_char1, value:dict[key:bigram_char2,value:probability of bigram]]\n",
        "                    > P[\"a\"][\"b\"] = 0.0001 (which stands of P(\"b\"|\"a\"))\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        bigram_total = {char1: sum(self.bigram_counts[char1].values()) for char1 in self.bigram_counts.keys()}\n",
        "        next_char_probabilities = {char1: {char2: (count+self.k)/(bigram_total[char1]+self.k*len(vocab)) for char2, count in self.bigram_counts[char1].items()} for char1 in self.bigram_counts.keys()}\n",
        "\n",
        "        # normalise the probabilities\n",
        "        next_char_probabilities = {char1: {char2: prob/sum(next_char_probabilities[char1].values()) for char2, prob in next_char_probabilities[char1].items()} for char1 in next_char_probabilities.keys()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model.\n",
        "        Be careful with cases for which probability of the name is zero.\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[name[i-1]][name[i]]) if name[i-1] in next_char_probabilities and name[i] in next_char_probabilities[name[i-1]] else 0 for i in range(1, len(name))])\n",
        "\n",
        "        return name_log_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Hu1YFQxjWvz",
        "outputId": "ef3d07c8-420b-4dee-d04b-ce6df0f8705d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "smoothed bigram train perplexity: 7.66338530194942\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "smoothed_bigram_model = LaplaceSmoothedBigramModel(train_text, k=BIGRAM_LAPLACE_K)\n",
        "\n",
        "# check the perplexity of the bigram model on training data\n",
        "print('smoothed bigram train perplexity:',\n",
        "      smoothed_bigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR0Su_WS8uhm",
        "outputId": "c7d4a34b-2e94-40e6-8ce8-fdc22a3783b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 2-gram on validation perplexity: 1.6528329929509393\n",
            "EVALUATION 2-gram generated names are ashisaf, mldamaa, mjehuka, gunitar, dhunsha\n",
            "EVALUATION 2-gram generated names with prefix <s><s>sh are <s><s>shimal, <s><s>shyaen, <s><s>shalda, <s><s>shahal, <s><s>shanam\n",
            "EVALUATION 2-gram top most likely chars after <s><s>aa are </s>, n, r, m, l\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=smoothed_bigram_model, ngram=2, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4fhvedn1A0e"
      },
      "source": [
        "**Interpolation**\n",
        "- what are good values for `lambdas` in interpolation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MICCLx7yxxg-"
      },
      "outputs": [],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please feel free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated names and perplexity\n",
        "\n",
        "BIGRAM_LAMBDAS = (0.4, 0.6) # lambdas for interpolation smoothing in bigram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDxCF6oayhc_"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementation of a bigram model with interpolation smoothing\n",
        "\"\"\"\n",
        "\n",
        "class InterpolationSmoothedBigramModel(BigramModel):\n",
        "\n",
        "    def __init__(self, train_text, lambdas):\n",
        "        super().__init__(train_text)\n",
        "        self.lambda_1, self.lambda_2 = lambdas\n",
        "        self.unigram_counts = get_unigram_counts(self.train_text)\n",
        "\n",
        "    # You should override ONLY those functions\n",
        "    # which calculate probability of a bigram.\n",
        "    # You can override get_next_char_probabilities\n",
        "    # or any other helper functions you use in BigramModel\n",
        "    # to calculate bigram probabilities.\n",
        "\n",
        "    # ADD YOUR CODE HERE\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Returns a probability distribution over all chars in the vocabulary.\n",
        "        Probability distribution should sum to one.\n",
        "\n",
        "        Returns:\n",
        "            P: dictionary or nested dictionary; Output format depends on n-gram\n",
        "            Examples:\n",
        "                for N=2 (bigram); dict[key:bigram_char1, value:dict[key:bigram_char2,value:probability of bigram]]\n",
        "                    > P[\"a\"][\"b\"] = 0.0001 (which stands of P(\"b\"|\"a\"))\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        bigram_total = {char1: sum(self.bigram_counts[char1].values()) for char1 in self.bigram_counts.keys()}\n",
        "        next_char_probabilities = {char1: {char2: (self.lambda_1*self.bigram_counts[char1][char2]/bigram_total[char1] + self.lambda_2*self.unigram_counts[char2]/sum(self.unigram_counts.values())) for char2 in self.bigram_counts[char1].keys()} for char1 in self.bigram_counts.keys()}\n",
        "\n",
        "        # normalise the probabilities\n",
        "        next_char_probabilities = {char1: {char2: prob/sum(next_char_probabilities[char1].values()) for char2, prob in next_char_probabilities[char1].items()} for char1 in next_char_probabilities.keys()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model.\n",
        "        Be careful with cases for which probability of the name is zero.\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[name[i-1]][name[i]]) if name[i-1] in next_char_probabilities and name[i] in next_char_probabilities[name[i-1]] else 0 for i in range(1, len(name))])\n",
        "\n",
        "        return name_log_probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOcXbCHE87nR",
        "outputId": "b64dae7a-868b-439f-f57a-eb1709e70045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "smoothed bigram train perplexity: 8.748174466325166\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "smoothed_bigram_model = InterpolationSmoothedBigramModel(train_text, lambdas=BIGRAM_LAMBDAS)\n",
        "\n",
        "# check the perplexity of the bigram model on training data\n",
        "print('smoothed bigram train perplexity:',\n",
        "      smoothed_bigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTbTOynX86dl",
        "outputId": "295ec525-df71-4dce-aad3-053ebb80153f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 2-gram on validation perplexity: 1.7159671877875684\n",
            "EVALUATION 2-gram generated names are subbsis, shmaiid, alikiin, naataae, mgaauus\n",
            "EVALUATION 2-gram generated names with prefix <s><s>sh are <s><s>shhain, <s><s>shlhih, <s><s>shynrk, <s><s>shndkh, <s><s>shntut\n",
            "EVALUATION 2-gram top most likely chars after <s><s>aa are </s>, n, a, r, m\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=smoothed_bigram_model, ngram=2, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjSDZS0s9lZi"
      },
      "outputs": [],
      "source": [
        "# Release models we don't need any more.\n",
        "del bigram_model\n",
        "del smoothed_bigram_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjVndxFa1iGi"
      },
      "source": [
        "## 1.3 Trigram (smoothed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw_rGQSDMC6S"
      },
      "outputs": [],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please feel free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated names and perplexity\n",
        "\n",
        "TRIGRAM_LAMBDAS = (0.5, 0.3, 0.2) # lambdas for interpolation smoothing in trigram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vagtEVtp1kLN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implementaion of a Trigram Model with interpolation smoothing.\n",
        "\"\"\"\n",
        "\n",
        "class TrigramModel(NGramLanguageModel):\n",
        "    def __init__(self, train_text):\n",
        "        \"\"\"\n",
        "        Initialise and train the model with train_text.\n",
        "\n",
        "        Args:\n",
        "            train_text [list of list]: list of tokenised names\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Initialise the train_text\n",
        "        super().__init__(train_text)\n",
        "        self.trigram_counts = get_trigram_counts(train_text)\n",
        "        self.train_text = train_text\n",
        "        self.unigram_counts = get_unigram_counts(self.train_text)\n",
        "        self.bigram_counts = get_bigram_counts(train_text)\n",
        "        self.lambda_1, self.lambda_2, self.lambda_3 = TRIGRAM_LAMBDAS\n",
        "\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Returns a probability distribution over all chars in the vocabulary.\n",
        "        Probability distribution should sum to one.\n",
        "\n",
        "        Returns:\n",
        "            P: dictionary or nested dictionary; Output format depends on n-gram\n",
        "            Examples:\n",
        "                for N=1 (unigram); dict[key:unigram,value:probability of unigram]\n",
        "                    > P[\"a\"] = 0.0001\n",
        "                for N=2 (bigram); dict[key:bigram_char1, value:dict[key:bigram_char2,value:probability of bigram]]\n",
        "                    > P[\"a\"][\"b\"] = 0.0001 (corresponding to P(b|a))\n",
        "                for N=3 (trigram); dict[dict[dict]]\n",
        "                    > P[\"a\"][\"b\"][\"c\"] = 0.0001 (corresponding to P(c|ab))\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        trigram_total = {char1: {char2: sum(self.trigram_counts[char1][char2].values()) for char2 in self.trigram_counts[char1].keys()} for char1 in self.trigram_counts.keys()}\n",
        "        next_char_probabilities = {char1: {char2: {char3: (self.lambda_1*self.trigram_counts[char1][char2][char3]/trigram_total[char1][char2] + self.lambda_2*self.bigram_counts[char2][char3]/sum(self.bigram_counts[char2].values()) + self.lambda_3*self.unigram_counts[char3]/sum(self.unigram_counts.values())) for char3 in self.trigram_counts[char1][char2].keys()} for char2 in self.trigram_counts[char1].keys()} for char1 in self.trigram_counts.keys()}\n",
        "\n",
        "        # normalise the probabilities\n",
        "        next_char_probabilities = {char1: {char2: {char3: prob/sum(next_char_probabilities[char1][char2].values()) for char3, prob in next_char_probabilities[char1][char2].items()} for char2, prob in next_char_probabilities[char1].items()} for char1, prob in next_char_probabilities.items()}\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "\n",
        "    def get_name_log_probability(self, name):\n",
        "        \"\"\"\n",
        "        Calculates the log probability of name according to the n-gram model.\n",
        "        Be careful with cases for which probability of the name is zero.\n",
        "\n",
        "        Args:\n",
        "            name [list]: list of tokens\n",
        "\n",
        "        Returns:\n",
        "            Log probability of the name [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        name_log_probability = sum([np.log(next_char_probabilities[name[i-2]][name[i-1]][name[i]]) if name[i-2] in next_char_probabilities and name[i-1] in next_char_probabilities[name[i-2]] and name[i] in next_char_probabilities[name[i-2]][name[i-1]] else 0 for i in range(2, len(name))])\n",
        "\n",
        "        return name_log_probability\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on a text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list]: a list of string tokens\n",
        "\n",
        "        Returns:\n",
        "            perplexity of the given text [float]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        count = 0\n",
        "\n",
        "        for name in self.train_text:\n",
        "            count = count + len(name)\n",
        "\n",
        "        perplexity = np.exp(-sum([self.get_name_log_probability(name) for name in text])/count)\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n=MAX_NAME_LENGTH, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            list of generated names [list]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        names = []\n",
        "\n",
        "        for _ in range(k):\n",
        "            name = [START, START] if prefix is None else prefix.copy()\n",
        "            while name[-1] != END and len(name) < n:\n",
        "                if prefix is None:\n",
        "                    a = np.random.choice(list(self.get_next_char_probabilities().keys()))\n",
        "                    b = np.random.choice(list(self.get_next_char_probabilities()[a].keys()))\n",
        "                    next_char_probs = self.get_next_char_probabilities()[a][b]\n",
        "                    next_char = np.random.choice(list(next_char_probs.keys()), p=list(next_char_probs.values()))\n",
        "                    if next_char != '<s>' and next_char != '</s>':\n",
        "                        name.append(next_char)\n",
        "                else:\n",
        "                    next_char_probs = self.get_next_char_probabilities()[name[-2]][name[-1]]\n",
        "                    next_char = np.random.choice(list(next_char_probs.keys()), p=list(next_char_probs.values()))\n",
        "                    if next_char != '<s>' and next_char != '</s>':\n",
        "                        name.append(next_char)\n",
        "            if prefix is None:\n",
        "                names.append(\"\".join(name[2:]))\n",
        "            else:\n",
        "                names.append(\"\".join(name[0:]))\n",
        "\n",
        "        return names\n",
        "\n",
        "        # names = []\n",
        "        # for _ in range(k):\n",
        "        #     name = prefix\n",
        "        #     while name[-1] != END and len(name) < n:\n",
        "        #         #name.append(np.random.choice(list(self.get_next_char_probabilities()[name[-2]][name[-1]].keys()), p=list(self.get_next_char_probabilities()[name[-2]][name[-1]].values())))\n",
        "        #         next_char_probs = self.get_next_char_probabilities()[name[-2]][name[-1]]\n",
        "        #         next_char = np.random.choice(list(next_char_probs.keys()), p=list(next_char_probs.values()))\n",
        "        #         name.append(next_char)\n",
        "        #     names.append(\"\".join(name[1:]))\n",
        "\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        next_char_probabilities = self.get_next_char_probabilities()\n",
        "        most_likely_chars = sorted(next_char_probabilities[sequence[-2]][sequence[-1]], key=next_char_probabilities[sequence[-2]][sequence[-1]].get, reverse=True)[:k]\n",
        "\n",
        "        return most_likely_chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKzFQN7BLNet"
      },
      "source": [
        "#### Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1VPc3Y1C_f2",
        "outputId": "aee7ebb2-377d-49d0-e71c-722c67d472ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trigram train perplexity: 4.460615866489244\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "trigram_model = TrigramModel(train_text)\n",
        "\n",
        "print('trigram train perplexity:',\n",
        "      trigram_model.get_perplexity(train_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzmJeanF9MV1",
        "outputId": "b0dac7ae-a4bb-4377-986e-ec85c30adba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 3-gram on validation perplexity: 1.3842457143115143\n",
            "EVALUATION 3-gram generated names are ahraha, uikaje, ihahae, eheual, aiahot\n",
            "EVALUATION 3-gram generated names with prefix <s><s>sh are <s><s>shanka, <s><s>shupam, <s><s>shatad, <s><s>shadma, <s><s>sholoo\n",
            "EVALUATION 3-gram top most likely chars after <s><s>aa are n, s, </s>, r, m\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "eval_ngram_model(model=trigram_model, ngram=3, ds=validation_text, ds_name='validation', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CO8n8Nfw9qSN"
      },
      "outputs": [],
      "source": [
        "# Release models we don't need any more.\n",
        "del trigram_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIY6joZm4U7Q"
      },
      "source": [
        "# Module 2: Neural Language Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR0QIMEkZFnc"
      },
      "source": [
        "## 2.1 Neural N-gram Language Model\n",
        "\n",
        "For this part of the assignment, you should use the GPU (you can do this by changing the runtime of this notebook).\n",
        "\n",
        "In this section, you will implement a neural version of an n-gram model.  The model will use a simple feedforward neural network that takes the previous `n-1` chars and outputs a distribution over the next char.\n",
        "\n",
        "You will use PyTorch to implement the model.  We've provided a little bit of code to help with the data loading using [PyTorch's data loaders](https://pytorch.org/docs/stable/data.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzMvPQ-2V_hZ"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import os, sys\n",
        "import json\n",
        "from functools import partial\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvfDLLQO6Hrc"
      },
      "outputs": [],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "def collate_ngram(batch, text_pipeline):\n",
        "    \"\"\"\n",
        "    Converts the text in the batch to tokens\n",
        "    and maps the tokens to indices in the vocab.\n",
        "    The text in the batch is a list of ngrams\n",
        "    i.e. if N=3, then text contains 3 tokens in a list\n",
        "    and batch is a list of such texts.\n",
        "\n",
        "    Returns:\n",
        "        batch_input [pytorch tensor]:\n",
        "            input for n-gram model with size batch_size*(ngram-1)\n",
        "        batch_output [pytorch tensor]:\n",
        "            output for n-gram model with size batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    batch_input, batch_output = [], []\n",
        "\n",
        "    # Process each text in the batch\n",
        "    for text in batch:\n",
        "        token_id_sequence = text_pipeline(text)\n",
        "        # last token is the output, and\n",
        "        #  pervious ngram-1 tokens are inputs\n",
        "        output = token_id_sequence.pop()\n",
        "        input = token_id_sequence\n",
        "        batch_input.append(input)\n",
        "        batch_output.append(output)\n",
        "\n",
        "    # Convert lists to PyTorch tensors and moves to the gpu (if using)\n",
        "    batch_input = torch.tensor(batch_input, dtype=torch.long)\n",
        "    batch_output = torch.tensor(batch_output, dtype=torch.long)\n",
        "    if USE_CUDA:\n",
        "        batch_input = batch_input.cuda()\n",
        "        batch_output = batch_output.cuda()\n",
        "\n",
        "    return batch_input, batch_output\n",
        "\n",
        "\n",
        "def get_dataloader(input_text, vocab, ngram, batch_size, shuffle):\n",
        "    \"\"\"\n",
        "    Creates a dataloader for the n-gram model which\n",
        "    takes in a list of list of tokens, appends the START token\n",
        "    at the starting of each text, and converts text into ngrams.\n",
        "\n",
        "    Example: For a trigram model, the list of characters are\n",
        "        [\"n\", \"a\", \"v\", \"r\"]\n",
        "    will be converted into lists\n",
        "        [\"n\", \"a\", \"v\"], [\"a\", \"v\", \"r\"]\n",
        "\n",
        "    For each ngram, first ngram-1 tokens are input and last token\n",
        "    is the output. Each token is converted into a index in the vocab.\n",
        "    The dataloader generates a batch of input, output pairs as\n",
        "    pytorch tensors.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        input_text [list[list[str]]]: list of list of tokens\n",
        "        vocab [torchtext.vocab]: vocabulary of the corpus\n",
        "    \"\"\"\n",
        "\n",
        "    ngram_sequences = []\n",
        "    for text in input_text:\n",
        "        if text[0] == START:\n",
        "            text = [START]*(N_GRAM_LENGTH-2) + text\n",
        "        else:\n",
        "            text = [START]*(N_GRAM_LENGTH-1) + text\n",
        "\n",
        "        # Create training pairs for each char in the text\n",
        "        for idx in range(len(text) - ngram + 1):\n",
        "            ngram_sequence = text[idx : (idx + ngram)]\n",
        "            ngram_sequences.append(ngram_sequence)\n",
        "\n",
        "    text_pipeline = lambda x: vocab(x)\n",
        "    collate_fn = collate_ngram\n",
        "\n",
        "    # creates a DataLoader for the dataset\n",
        "\n",
        "    \"\"\"\n",
        "    dataloader documentation\n",
        "    https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
        "    \"\"\"\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        ngram_sequences,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=partial(collate_fn, text_pipeline=text_pipeline),\n",
        "        )\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgzJr_pRQnyt"
      },
      "source": [
        "#### FNN Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYXn-sEtWH-A"
      },
      "source": [
        "**Feed-forward Neural Language Modelling**\n",
        "\n",
        "Like the n-gram LM, the feedforward neural LM approximates the probability of a char given the entire prior context $P(w_t|w_{1:t−1})$ by approximating based on the $N-1$ previous chars:\n",
        "$$P(w_t|w_1,...,w_{t−1}) ≈ P(w_t|w_{t−N+1},...,w_{t−1})$$\n",
        "\n",
        "\n",
        "Implement the FNN LM given in this paper: [Neural Probabilistic Language Model](https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
        "\n",
        "The architecture of the FNN can be described by the equation and figure:\n",
        "\n",
        "$$y = b + W x + U \\text t \\text a \\text n \\text h (d + H x)$$\n",
        "\n",
        "- $x$ is of size $(ngram-1)*m$ where $m$ is the size embedding dimensions\n",
        "- $y$ is of size $V*1$ where $V$ is the vocabulary size\n",
        "\n",
        "![FNN_LM](https://drive.google.com/uc?id=1aQhkXjWelHfiBfmBQV3z5TjHFNMtqtzT)\n",
        "\n",
        "\n",
        "**Some tips**:\n",
        "- embed the chars with dimension $m$ (example, $60$), then flatten into a single embedding for  $n-1$  chars (with size  $(n-1)*m$ )\n",
        "- you can use Adam or Stochastic Gradient Descent (SGD) for optimising the cross entropy loss\n",
        "- If you are using SGD, you may want to use momentum, and a learning rate scheduler\n",
        "- do early stopping based on validation set loss or perplexity\n",
        "\n",
        "**Important**: Fix seed as 42 whenever performing any randomized operations, e.g., initializing ML models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkfUtubuZP-g"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implemenation of a PyTorch Module that holds the neural network for your model\n",
        "\n",
        "\"\"\"\n",
        "class FNN_LM(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, emb_size, hid_size, ngram):\n",
        "        super(FNN_LM, self).__init__()\n",
        "        self.ngram = ngram\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        self.emb_size = emb_size\n",
        "        self.l1 = nn.Linear((ngram-1)*emb_size,hid_size)\n",
        "        self.l2 = nn.Linear(hid_size,vocab_size,bias=False)\n",
        "        self.l3 = nn.Linear((ngram-1)*emb_size,vocab_size)\n",
        "        self.embedding_layer = nn.Embedding(vocab_size,emb_size)\n",
        "\n",
        "\n",
        "    def forward(self, chars):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            chars: this is a tensor of inputs with shape [batch_size x ngram-1]\n",
        "\n",
        "        Returns:\n",
        "            logits: a tensor of log probabilities with shape [batch_size x vocab_size]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        x = self.embedding_layer(chars)\n",
        "        X = x.view(-1,(self.ngram-1)*self.emb_size)\n",
        "        l_1 = torch.tanh(self.l1(X))\n",
        "        logits = self.l3(X)+self.l2(l_1)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU8cU_UURhM6"
      },
      "source": [
        "**The following is the Trainer class for the FNN LM. Add your code for the `training` and `validation` loops.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vTGLbaYCXz6"
      },
      "outputs": [],
      "source": [
        "from re import X\n",
        "class NeuralNGramTrainer:\n",
        "    \"\"\"\n",
        "    NeuralNGramTrainer wraps FNN_LM to handle training and evaluation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # NOTE: you are free to add additional inputs/functions\n",
        "    # to NeuralNGramTrainer to make training better\n",
        "    # make sure to define and add it within the input\n",
        "    # and initialization if you are using any additional inputs\n",
        "    # for usage in the function\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        ngram,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        train_dataloader,\n",
        "        valid_dataloader,\n",
        "        epochs,\n",
        "        use_cuda,\n",
        "        vocab,\n",
        "        model_dir\n",
        "    ):\n",
        "\n",
        "        self.ngram = ngram\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.valid_dataloader = valid_dataloader\n",
        "        self.use_cuda = use_cuda\n",
        "        self.model_dir = model_dir\n",
        "        self.loss = {\"train\": [], \"val\": []}\n",
        "        self.vocab = vocab\n",
        "\n",
        "        self.validity_loss_count = []\n",
        "\n",
        "        # Move the model to GPU if available\n",
        "        if self.use_cuda:\n",
        "            self.model = self.model.cuda()\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains the model with train_dataloader and validates using valid_dataloader\n",
        "\n",
        "        \"\"\"\n",
        "        # You may change the input arguments to this function,\n",
        "        # but make sure to also change the code wherever this function is called\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        # FOR TRAINING & VALIDATION\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            # Training phase\n",
        "            self.model.train()\n",
        "            self.epoch_train(self.train_dataloader)\n",
        "\n",
        "            # Validation phase\n",
        "            self.model.eval()\n",
        "\n",
        "\n",
        "            validity_loss = 0\n",
        "            a = 0\n",
        "            for batch in self.valid_dataloader:\n",
        "                loss_cpu_item = 0\n",
        "\n",
        "                x_batch,y_batch = batch\n",
        "                with torch.no_grad():\n",
        "                    y_pred = self.model(x_batch)\n",
        "                    loss = self.criterion(y_pred,y_batch)\n",
        "                    loss_cpu_item = loss.detach().clone().cpu().item()\n",
        "\n",
        "                validity_loss += len(batch)*loss_cpu_item\n",
        "                a  = a + len(batch)\n",
        "                validity_loss = validity_loss / a\n",
        "                self.loss[\"val\"].append(validity_loss)\n",
        "                self.validity_loss_count.append(len(self.loss[\"train\"])-1)\n",
        "\n",
        "\n",
        "            # Display results\n",
        "            self.plot_losses()\n",
        "            print(f\"Epoch {epoch + 1}/{self.epochs}\")\n",
        "            print(f\"Train Loss: {self.loss['train'][-1]:.4f}\")\n",
        "            print(f\"Validation Loss: {self.loss['val'][-1]:.4f}\")\n",
        "\n",
        "    def epoch_train(self,d):\n",
        "        for batch in d:\n",
        "            x_batch,y_batch = batch\n",
        "            y_pred = self.model(x_batch)\n",
        "            loss = self.criterion(y_pred,y_batch)\n",
        "            loss.backward()\n",
        "            self.loss[\"train\"].append(loss.detach().clone().cpu().item())\n",
        "            self.optimizer.step()\n",
        "            if hasattr(self.optimizer,\"sched\"):self.optimizer.sched.step()\n",
        "            self.optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_losses(self):\n",
        "        \"\"\"\n",
        "        Plots the training and validation losses\n",
        "        \"\"\"\n",
        "        plt.plot(self.loss['train'], label='train_ppl')\n",
        "        plt.plot(self.validity_loss_count,self.loss['val'], label='val_ppl')\n",
        "        plt.legend()\n",
        "        plt.show\n",
        "\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Save final model to directory\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        model_path = os.path.join(self.model_dir, \"model.pt\")\n",
        "        torch.save(self.model, model_path)\n",
        "\n",
        "\n",
        "    def save_loss(self):\n",
        "        \"\"\"\n",
        "        Save train/val loss as json file to the directory\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        loss_path = os.path.join(self.model_dir, \"loss.json\")\n",
        "        with open(loss_path, \"w\") as fp:\n",
        "            json.dump(self.loss, fp)\n",
        "\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Return a dictionary of probabilities for each char in the vocabulary\n",
        "        with a default starting sequence of [START]*(ngram-1)\n",
        "        Example:\n",
        "            If ngram=3, then default starting sequence for which\n",
        "            probabilities have to be returned is\n",
        "            [START, START]\n",
        "\n",
        "        Returns:\n",
        "            dictionary with key: char, value: probability\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # Creating token_ids for n-gram language model\n",
        "        start_token_ids = torch.tensor([vocab[c] for c in [START] * (self.ngram - 1)], dtype=torch.long).reshape(1, self.ngram - 1)\n",
        "\n",
        "        # Move tensor to GPU if applicable\n",
        "        if self.use_cuda:\n",
        "            start_token_ids = start_token_ids.cuda()\n",
        "\n",
        "        # Set the model to evaluation mode and calculate probabilities\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            probabilities = torch.softmax(self.model(start_token_ids), dim=1)[0]\n",
        "\n",
        "\n",
        "\n",
        "        # Create a dictionary of next character probabilities\n",
        "        next_char_probabilities = {vocab.get_itos()[i]: probabilities[i] for i in range(len(probabilities))}\n",
        "\n",
        "\n",
        "        return next_char_probabilities\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n=MAX_NAME_LENGTH, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            list of generated names [list[str]]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "        # Set the model to evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # If prefix is not provided, initialize it with START tokens\n",
        "        if prefix is None:\n",
        "            prefix = [START] * (self.ngram - 1)\n",
        "\n",
        "        # Ensure the prefix length matches the required n-gram length\n",
        "        if len(prefix) != self.ngram - 1:\n",
        "            prefix = [START] * (self.ngram - 1 - len(prefix)) + prefix\n",
        "\n",
        "        # List to store generated names\n",
        "        names = []\n",
        "\n",
        "        # Generate k names\n",
        "        for i in range(k):\n",
        "            current_name = prefix.copy()\n",
        "            name_length = 0\n",
        "\n",
        "            while name_length < n:\n",
        "                # Convert current name to token_ids\n",
        "                token_ids = torch.tensor([vocab[c] for c in current_name[-(self.ngram - 1):]], dtype=torch.long).reshape(1, -1)\n",
        "\n",
        "                # Move tensor to GPU if applicable\n",
        "                if self.use_cuda:\n",
        "                    token_ids = token_ids.cuda()\n",
        "\n",
        "                # Calculate probabilities and sample the next character\n",
        "                with torch.no_grad():\n",
        "                    probabilities = torch.softmax(self.model(token_ids), dim=1)[0].cpu().numpy()\n",
        "                next_char = vocab.get_itos()[np.random.choice(len(probabilities), p=probabilities)]\n",
        "\n",
        "                # Break if END token is encountered\n",
        "                if next_char == END:\n",
        "                    break\n",
        "\n",
        "                # Append the next character to the current name\n",
        "                current_name.append(next_char)\n",
        "                name_length += 1\n",
        "\n",
        "            # Add the generated name to the list\n",
        "            names.append(\"\".join(current_name))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # don't forget self.model.eval()\n",
        "\n",
        "        return names\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list[list[str]]]: list of tokenised names\n",
        "            > Example:\n",
        "            [['<s>', 'a', 'a', 'b', 'i', 'd', '</s>'],\n",
        "            ['<s>', 'a', 'a', 'b', 'i', 'd', 'a', '</s>']]\n",
        "\n",
        "        Returns:\n",
        "            perplexity [float]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "# Set the model to evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        # Create a DataLoader for the text\n",
        "        data_loader = get_dataloader(text, vocab, self.ngram, 256, False)\n",
        "\n",
        "        # Initialize variables for entropy calculation\n",
        "        entropy, n = 0, 0\n",
        "\n",
        "        # Calculate entropy using the DataLoader\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in data_loader:\n",
        "                # Forward pass to get logits\n",
        "                logits = self.model(inputs)\n",
        "\n",
        "                # Calculate probabilities for the correct predictions\n",
        "                probabilities = torch.softmax(logits, dim=1)[range(len(inputs)), targets.ravel()]\n",
        "\n",
        "                # Move probabilities to CPU if applicable\n",
        "                if self.use_cuda:\n",
        "                    probabilities = probabilities.cpu()\n",
        "\n",
        "                # Convert probabilities to numpy array\n",
        "                probabilities = probabilities.numpy()\n",
        "\n",
        "                # Update entropy\n",
        "                entropy -= np.sum(np.log(probabilities))\n",
        "                n += len(inputs)\n",
        "\n",
        "        # Calculate average entropy and perplexity\n",
        "        average_entropy = entropy / n\n",
        "        perplexity = np.exp(average_entropy)\n",
        "\n",
        "# Note: You may want to use the DataLoader directly for better efficiency\n",
        "# Don't forget to set the model back to evaluation mode with self.model.eval()\n",
        "\n",
        "\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        # Retrieve the index-to-token mapping\n",
        "        index_to_token = vocab.get_itos()\n",
        "\n",
        "        # Ensure the sequence length matches the required n-gram length\n",
        "        if len(sequence) != self.ngram - 1:\n",
        "            sequence = [START] * (self.ngram - 1 - len(sequence)) + sequence\n",
        "\n",
        "        # Convert the last n-1 tokens of the sequence to token_ids\n",
        "        token_ids = torch.tensor([vocab[c] for c in sequence[-(self.ngram - 1):]], dtype=torch.long).reshape(1, -1)\n",
        "\n",
        "        # Move tensor to GPU if applicable\n",
        "        if self.use_cuda:\n",
        "            token_ids = token_ids.cuda()\n",
        "\n",
        "        # Forward pass to get logits and probabilities\n",
        "        with torch.no_grad():\n",
        "            logits = self.model(token_ids)\n",
        "            probabilities = torch.softmax(logits, dim=1)\n",
        "\n",
        "            # Move probabilities to CPU if applicable\n",
        "            if self.use_cuda:\n",
        "                probabilities = probabilities.cpu()\n",
        "\n",
        "            # Convert probabilities to numpy array\n",
        "            probs_array = probabilities.numpy()\n",
        "\n",
        "        # Sort characters based on probabilities in descending order\n",
        "        char_prob_pair = sorted(zip(index_to_token, list(probs_array.ravel())), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Get the top k most likely characters\n",
        "        most_likely_chars = [c for c, _ in char_prob_pair[:k]]\n",
        "\n",
        "\n",
        "        # don't forget self.model.eval()\n",
        "\n",
        "        return most_likely_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNjAGhY0CXz8",
        "outputId": "6487c4e4-0e40-44e2-92e4-e2e97f6218c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available: True\n"
          ]
        }
      ],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please feel free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated names and perplexity\n",
        "\n",
        "MAX_NAME_LENGTH = 7 # maximum length of name for generation\n",
        "\n",
        "# Remember to fix seed as 42\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# check if GPU is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "print(f\"GPU is available: {USE_CUDA}\")\n",
        "\n",
        "N_GRAM_LENGTH = 5 # The length of the n-gram (N_GRAM_LENGTH=3 for trigram)\n",
        "EMB_SIZE = 16 # The size of the embedding\n",
        "HID_SIZE = 64 # The size of the hidden layer\n",
        "EPOCHS = 15\n",
        "BATCH_SIZE = 1024\n",
        "SHUFFLE = True # if dataset should be shuffled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtObQOzcCXz9",
        "outputId": "edcc2820-f5c4-4676-b966-3c18fa197235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131\n"
          ]
        }
      ],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "# Get data iterator and build vocabulary from input text\n",
        "train_text, vocab = get_tokenised_text_and_vocab(ds_type='train')\n",
        "validation_text, _ = get_tokenised_text_and_vocab(ds_type='valid', vocab=vocab)\n",
        "\n",
        "# Check the size of vocabulary\n",
        "vocab_size = len(vocab.get_stoi())\n",
        "print(vocab_size)\n",
        "\n",
        "# Load training and validation dataloaders\n",
        "train_dataloader = get_dataloader(train_text, vocab, ngram = N_GRAM_LENGTH, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
        "valid_dataloader = get_dataloader(validation_text, vocab, ngram = N_GRAM_LENGTH, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VS8eky0_hVnx",
        "outputId": "3a47b1de-2ffc-43a1-8667-06f4afd67a6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "Train Loss: 3.5852\n",
            "Validation Loss: 0.3920\n",
            "Epoch 2/15\n",
            "Train Loss: 2.4202\n",
            "Validation Loss: 0.3257\n",
            "Epoch 3/15\n",
            "Train Loss: 2.2432\n",
            "Validation Loss: 0.2986\n",
            "Epoch 4/15\n",
            "Train Loss: 2.2905\n",
            "Validation Loss: 0.2861\n",
            "Epoch 5/15\n",
            "Train Loss: 2.1315\n",
            "Validation Loss: 0.2667\n",
            "Epoch 6/15\n",
            "Train Loss: 2.0612\n",
            "Validation Loss: 0.3169\n",
            "Epoch 7/15\n",
            "Train Loss: 2.1784\n",
            "Validation Loss: 0.2773\n",
            "Epoch 8/15\n",
            "Train Loss: 2.1012\n",
            "Validation Loss: 0.2735\n",
            "Epoch 9/15\n",
            "Train Loss: 2.1225\n",
            "Validation Loss: 0.2968\n",
            "Epoch 10/15\n",
            "Train Loss: 2.1481\n",
            "Validation Loss: 0.2864\n",
            "Epoch 11/15\n",
            "Train Loss: 2.0666\n",
            "Validation Loss: 0.2883\n",
            "Epoch 12/15\n",
            "Train Loss: 1.8790\n",
            "Validation Loss: 0.2661\n",
            "Epoch 13/15\n",
            "Train Loss: 1.7865\n",
            "Validation Loss: 0.2870\n",
            "Epoch 14/15\n",
            "Train Loss: 2.0527\n",
            "Validation Loss: 0.2803\n",
            "Epoch 15/15\n",
            "Train Loss: 2.0389\n",
            "Validation Loss: 0.2771\n",
            "Training finished.\n",
            "Model artifacts saved to folder: Ashhar_Zaman_22881/fnn\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# This is the part where you should train your FNN_LM model\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "\n",
        "# Initialise the model, optimizer, learning rate scheduler (optional), and loss criteria\n",
        "model = FNN_LM(vocab_size=vocab_size, emb_size=EMB_SIZE, hid_size=HID_SIZE, ngram=N_GRAM_LENGTH)\n",
        "# Move the model to GPU if available\n",
        "if USE_CUDA:\n",
        "  model = model.cuda()\n",
        "\n",
        "lr = 0.01\n",
        "weight_decay = 0.1\n",
        "optimizer = optim.AdamW(model.parameters(),lr=lr,weight_decay=weight_decay)\n",
        "optimizer.sched = optim.lr_scheduler.OneCycleLR(optimizer,lr,EPOCHS*len(train_dataloader))\n",
        "criterion = nn.functional.cross_entropy\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "model_dir = 'Ashhar_Zaman_22881/fnn'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# NOTE: if you are **optionally** using additional options for the trainer\n",
        "# (e.g., a training scheduler), please add them below.\n",
        "trainer = NeuralNGramTrainer(\n",
        "        ngram=N_GRAM_LENGTH,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        train_dataloader=train_dataloader,\n",
        "        valid_dataloader=valid_dataloader,\n",
        "        epochs=EPOCHS,\n",
        "        use_cuda=USE_CUDA,\n",
        "        model_dir=model_dir,\n",
        "        vocab=vocab)\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "print(\"Training finished.\")\n",
        "\n",
        "trainer.save_model()\n",
        "trainer.save_loss()\n",
        "vocab_path = os.path.join(model_dir, \"vocab.pt\")\n",
        "torch.save(vocab, vocab_path)\n",
        "print(\"Model artifacts saved to folder:\", model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0APUqz7Nj81"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZNU7a17LXUq",
        "outputId": "15e54044-906d-41f5-d72d-88471a68f870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EVALUATION probability distribution is valid: True\n",
            "EVALUATION of 5-gram on valid perplexity: 14.105714302256239\n",
            "EVALUATION 5-gram generated names are <s><s><s><s>faloh, <s><s><s><s>kajana, <s><s><s><s>raima, <s><s><s><s>tamitak, <s><s><s><s>ajisin\n",
            "EVALUATION 5-gram generated names with prefix <s><s>sh are <s><s>sharjnasai, <s><s>sharindeen, <s><s>shaha, <s><s>sharani, <s><s>shaula\n",
            "EVALUATION 5-gram top most likely chars after <s><s>aa are s, n, m, r, b\n"
          ]
        }
      ],
      "source": [
        "eval_ngram_model(trainer, ngram=N_GRAM_LENGTH, ds=validation_text, ds_name='valid', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5, is_neural=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_7sBsq2S73m"
      },
      "source": [
        "Load your saved model and generate a few names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQqORG-xXSPz",
        "outputId": "20565e81-9e41-4250-9103-b6bf08173da9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "aashaniran, aash, aashana, aashilak, aash\n"
          ]
        }
      ],
      "source": [
        "START = \"<s>\"   # Start-of-name token\n",
        "END = \"</s>\"    # End-of-name token\n",
        "UNK = \"<unk>\"   # token representing out of unknown (or out of vocabulary) tokens\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "folder = 'Ashhar_Zaman_22881/fnn'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the saved model\n",
        "model = torch.load(f\"{folder}/model.pt\", map_location=device)\n",
        "vocab = torch.load(f\"{folder}/vocab.pt\")\n",
        "\n",
        "# NOTE: if you are **optionally** using additional options for the trainer\n",
        "# (e.g., a training scheduler), please add them below.\n",
        "trainer = NeuralNGramTrainer(\n",
        "        ngram=N_GRAM_LENGTH,\n",
        "        model=model,\n",
        "        optimizer=None,\n",
        "        criterion=None,\n",
        "        train_dataloader=None,\n",
        "        valid_dataloader=None,\n",
        "        epochs=None,\n",
        "        use_cuda=USE_CUDA,\n",
        "        model_dir=None,\n",
        "        vocab=vocab)\n",
        "\n",
        "# Generate a few names\n",
        "names = trainer.generate_names(k=5, n=MAX_NAME_LENGTH, prefix=['a','a','s','h'])\n",
        "print(\", \".join(names))\n",
        "\n",
        "# you may use this block to test if your model and vocab load properly,\n",
        "# and that your functions are able to generate sentences, calculate perplexity etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKmRzACIc9t6"
      },
      "outputs": [],
      "source": [
        "# Release models we don't need any more.\n",
        "del trainer\n",
        "del model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9ac9hccZPRW"
      },
      "source": [
        "## 2.2 Recurrent Neural Networks for Language Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mjlDppEdH5v"
      },
      "source": [
        "For this stage of the assignment, you will implement an RNN language model.\n",
        "\n",
        "Some tips:\n",
        "* use dropout\n",
        "* use the same weights for the embedding layer and the pre-softmax layer\n",
        "* train with Adam\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sW-hgdruZUbm"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Implemenation of a PyTorch Module that holds the RNN\n",
        "\n",
        "\"\"\"\n",
        "class RNN_LM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(RNN_LM, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        output, hidden = self.rnn(x)\n",
        "        output = self.fc(output[:, -1])\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6J-IkqyGZUZP"
      },
      "outputs": [],
      "source": [
        "class RNNTrainer:\n",
        "    \"\"\"\n",
        "    RNNTrainer wraps RNN_LM to handle training and evaluation.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # NOTE: you are free to add additional inputs/functions\n",
        "    # to RNNTrainer to make training better\n",
        "    # make sure to define and add it within the input\n",
        "    # and initialization if you are using any additional inputs\n",
        "    # for usage in the function\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        optimizer,\n",
        "        criterion,\n",
        "        train_dataloader,\n",
        "        valid_dataloader,\n",
        "        epochs,\n",
        "        use_cuda,\n",
        "        vocab,\n",
        "        model_dir\n",
        "    ):\n",
        "\n",
        "        self.model = model\n",
        "        self.epochs = epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.train_dataloader = train_dataloader\n",
        "        self.valid_dataloader = valid_dataloader\n",
        "        self.use_cuda = use_cuda\n",
        "        self.model_dir = model_dir\n",
        "        self.loss = {\"train\": [], \"val\": []}\n",
        "        self.vocab = vocab\n",
        "\n",
        "        # Move the model to GPU if available\n",
        "        if self.use_cuda:\n",
        "            self.model = self.model.cuda()\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"\n",
        "        Trains the model with train_dataloader and validates using valid_dataloader\n",
        "\n",
        "        \"\"\"\n",
        "        # You may change the input arguments to this function,\n",
        "        # but make sure to also change the code wherever this function is called\n",
        "\n",
        "        # ADD YOUR CODE HERE FOR TRAINING & VALIDATION\n",
        "\n",
        "        def train(self):\n",
        "            for epoch in range(self.epochs):\n",
        "                for inputs, targets in self.train_dataloader:\n",
        "                    if self.use_cuda:\n",
        "                        inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                    self.optimizer.zero_grad()\n",
        "                    outputs = self.model(inputs)\n",
        "                    loss = self.criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    self.optimizer.step()\n",
        "\n",
        "                    self.loss[\"train\"].append(loss.item())\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for inputs, targets in self.valid_dataloader:\n",
        "                        if self.use_cuda:\n",
        "                            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "\n",
        "                        outputs = self.model(inputs)\n",
        "                        loss = self.criterion(outputs, targets)\n",
        "\n",
        "                        self.loss[\"val\"].append(loss.item())\n",
        "\n",
        "\n",
        "    def save_model(self):\n",
        "        \"\"\"\n",
        "        Save final model to directory\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        model_path = os.path.join(self.model_dir, \"model.pt\")\n",
        "        torch.save(self.model, model_path)\n",
        "\n",
        "\n",
        "    def save_loss(self):\n",
        "        \"\"\"\n",
        "        Save train/val loss as json file to the directory\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        loss_path = os.path.join(self.model_dir, \"loss.json\")\n",
        "        with open(loss_path, \"w\") as fp:\n",
        "            json.dump(self.loss, fp)\n",
        "\n",
        "\n",
        "    def get_next_char_probabilities(self):\n",
        "        \"\"\"\n",
        "        Return a dictionary of probabilities for each char in the vocabulary\n",
        "        with a default starting sequence of [START]\n",
        "\n",
        "        Returns:\n",
        "            dictionary with key: char, value: probability\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            inputs = torch.tensor([self.vocab.get_stoi()['<s>']])\n",
        "            if self.use_cuda:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs = self.model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            next_char_probabilities = {char: prob for char, prob in zip(self.vocab.itos, probabilities.cpu().numpy())}\n",
        "        return next_char_probabilities\n",
        "\n",
        "\n",
        "    def generate_names(self, k, n, prefix=None):\n",
        "        \"\"\"\n",
        "        Given a prefix, generate k names according to the model.\n",
        "        The default prefix is None.\n",
        "\n",
        "        Args:\n",
        "            k [int]: Number of names to generate\n",
        "            n [int]: Maximum length (number of tokens) in the generated name\n",
        "            prefix [list of tokens]: Prefix after which the names have to be generated\n",
        "\n",
        "        Returns:\n",
        "            list of generated names [list[str]]\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # don't forget self.model.eval()\n",
        "\n",
        "        self.model.eval()\n",
        "        names = []\n",
        "        with torch.no_grad():\n",
        "            for _ in range(k):\n",
        "                name = [self.vocab.stoi['<s>']]\n",
        "                for _ in range(n):\n",
        "                    inputs = torch.tensor([name[-1]])\n",
        "                    if self.use_cuda:\n",
        "                        inputs = inputs.cuda()\n",
        "                    outputs = self.model(inputs)\n",
        "                    probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                    next_char = np.random.choice(len(self.vocab), p=probabilities.cpu().numpy())\n",
        "                    name.append(next_char)\n",
        "                    if next_char == self.vocab.stoi['</s>']:\n",
        "                        break\n",
        "                names.append(''.join(self.vocab.itos[i] for i in name[1:]))\n",
        "        return names\n",
        "\n",
        "\n",
        "    def get_perplexity(self, text):\n",
        "        \"\"\"\n",
        "        Returns the perplexity of the model on text as a float.\n",
        "\n",
        "        Args:\n",
        "            text [list[list[str]]]: list of tokenised names\n",
        "            > Example:\n",
        "            [['<s>', 'a', 'a', 'b', 'i', 'd', '</s>'],\n",
        "            ['<s>', 'a', 'a', 'b', 'i', 'd', 'a', '</s>']]\n",
        "\n",
        "        Returns:\n",
        "            perplexity [float]\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # you may want to use the dataloader here\n",
        "        # don't forget self.model.eval()\n",
        "\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for sentence in text:\n",
        "                inputs = torch.tensor([self.vocab.stoi[char] for char in sentence[:-1]])\n",
        "                targets = torch.tensor([self.vocab.stoi[char] for char in sentence[1:]])\n",
        "                if self.use_cuda:\n",
        "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = self.criterion(outputs, targets)\n",
        "                total_loss += loss.item()\n",
        "        perplexity = np.exp(total_loss / len(text))\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def get_most_likely_chars(self, sequence, k):\n",
        "        \"\"\"\n",
        "        Given a sequence of characters, outputs k most likely characters after the sequence.\n",
        "\n",
        "        Args:\n",
        "            sequence [list[str]]: list of characters\n",
        "            k [int]: number of most likely characters to return\n",
        "\n",
        "        Returns:\n",
        "            chars [list[str]]: *Ordered* list of most likely characters\n",
        "                        (with charcater at index 0 being the most likely and\n",
        "                        character at index k-1 being the least likely)\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        # ADD YOUR CODE HERE\n",
        "\n",
        "        # don't forget self.model.eval()\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            inputs = torch.tensor([self.vocab.stoi[char] for char in sequence])\n",
        "            if self.use_cuda:\n",
        "                inputs = inputs.cuda()\n",
        "            outputs = self.model(inputs)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            topk_probs, topk_indices = torch.topk(probabilities, k)\n",
        "            most_likely_chars = [self.vocab.itos[i] for i in topk_indices.cpu().numpy()]\n",
        "        return most_likely_chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI_ePpV_b-vC",
        "outputId": "d7849e6d-365e-4806-8548-8e6ca209d0ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available: True\n",
            "131\n"
          ]
        }
      ],
      "source": [
        "\"\"\"choose your hyperparameter and see the difference in performance\"\"\"\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "# Please feel free to play with these hyperparameters to see the effects on the\n",
        "# quality of generated names and perplexity\n",
        "\n",
        "MAX_NAME_LENGTH = 15 # maximum length of name for generation\n",
        "\n",
        "# Remember to fix seed as 42\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# check if GPU is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "print(f\"GPU is available: {USE_CUDA}\")\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "SHUFFLE = True # if dataset should be shuffled\n",
        "\n",
        "# Get data iterator and build vocabulary from input text\n",
        "train_text, vocab = get_tokenised_text_and_vocab(ds_type='train')\n",
        "validation_text, _ = get_tokenised_text_and_vocab(ds_type='valid', vocab=vocab)\n",
        "\n",
        "# Check the size of vocabulary\n",
        "vocab_size = len(vocab.get_stoi())\n",
        "print(vocab_size)\n",
        "\n",
        "# create the dataloaders for training and validation\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "\n",
        "train_dataloader = DataLoader(train_text, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
        "valid_dataloader = DataLoader(validation_text, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_8F2e4Rb-vE",
        "outputId": "a5345810-25c5-4e9a-8a58-eb1b01351fd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished.\n",
            "Model artifacts saved to folder: Ashhar_Zaman_22881/rnn\n"
          ]
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# CHANGE THE None VALUES TO YOUR DESIRED VALUES\n",
        "\n",
        "# Initialize the model\n",
        "# you may want to pass arguments to RNN_LM based on your implementation\n",
        "model = RNN_LM(vocab_size, embedding_dim=128, hidden_dim=256)\n",
        "# Move the model to GPU if available\n",
        "if USE_CUDA:\n",
        "  model = model.cuda()\n",
        "\n",
        "# Initialise the optimizer, learning rate scheduler (optional), and loss criteria\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "model_dir = 'Ashhar_Zaman_22881/rnn'\n",
        "\n",
        "if not os.path.exists(model_dir):\n",
        "    os.makedirs(model_dir)\n",
        "\n",
        "# NOTE: if you are **optionally** using additional options for the trainer\n",
        "# (e.g., a training scheduler), please add them below.\n",
        "trainer = RNNTrainer(\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        criterion=criterion,\n",
        "        train_dataloader=train_dataloader,\n",
        "        valid_dataloader=valid_dataloader,\n",
        "        epochs=EPOCHS,\n",
        "        use_cuda=USE_CUDA,\n",
        "        vocab=vocab,\n",
        "        model_dir=model_dir\n",
        "        )\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "print(\"Training finished.\")\n",
        "\n",
        "trainer.save_model()\n",
        "trainer.save_loss()\n",
        "vocab_path = os.path.join(model_dir, \"vocab.pt\")\n",
        "torch.save(vocab, vocab_path)\n",
        "print(\"Model artifacts saved to folder:\", model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1BDYq3OeMbc"
      },
      "source": [
        "### Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNGBYVYRtz4H"
      },
      "outputs": [],
      "source": [
        "## Please do not change anything in this code block.\n",
        "\n",
        "def eval_rnn_model(model, ds, ds_name, eval_prefixes, eval_sequences, num_names=5):\n",
        "    \"\"\"\n",
        "    Runs the following evaluations on n-gram models:\n",
        "    (1) checks if probability distribution returned by model.get_next_char_probabilities() sums to one\n",
        "    (2) checks the perplexity of the model\n",
        "    (3) generates names using model.generate_names()\n",
        "    (4) generates names given a prefix using model.generate_names()\n",
        "    (4) output most likely characters after a given sequence of chars using model.get_most_likely_chars()\n",
        "    \"\"\"\n",
        "\n",
        "    # (1) checks if probability distributions sum to one\n",
        "    is_valid = check_validity(model, 1, True)\n",
        "    print(f'EVALUATION probability distribution is valid: {is_valid}')\n",
        "\n",
        "    # (2) evaluate the perplexity of the model on the dataset\n",
        "    print(f'EVALUATION of RNN on {ds_name} perplexity:',\n",
        "        model.get_perplexity(ds))\n",
        "\n",
        "    # (3) generate a few names\n",
        "    generated_names = \", \".join(model.generate_names(k=num_names, n=MAX_NAME_LENGTH))\n",
        "    print(f'EVALUATION RNN generated names are {generated_names}')\n",
        "\n",
        "    # (4) generate a few names given a prefix\n",
        "    for prefix in eval_prefixes:\n",
        "        generated_names_with_prefix = \", \".join(model.generate_names(k=num_names, n=MAX_NAME_LENGTH, prefix=prefix))\n",
        "        prefix = ''.join(prefix)\n",
        "        print(f'EVALUATION RNN generated names with prefix {prefix} are {generated_names_with_prefix}')\n",
        "\n",
        "    # (5) get most likely characters after a sequence\n",
        "    for sequence in eval_sequences:\n",
        "        most_likely_chars = \", \".join(model.get_most_likely_chars(sequence=sequence, k=num_names))\n",
        "        sequence = \"\".join(sequence)\n",
        "        print(f\"EVALUATION RNN the top most likely chars after {sequence} are {most_likely_chars}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "GZD3LMk5eJmt",
        "outputId": "f3239675-e44f-45d3-b6ab-36f4bea826a8"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x1 and 256x131)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-cf852fa212c0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_rnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_prefixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_prefixes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-52-a22c392dbfd3>\u001b[0m in \u001b[0;36meval_rnn_model\u001b[0;34m(model, ds, ds_name, eval_prefixes, eval_sequences, num_names)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# (1) checks if probability distributions sum to one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_validity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'EVALUATION probability distribution is valid: {is_valid}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6d38dc158436>\u001b[0m in \u001b[0;36mcheck_validity\u001b[0;34m(model, ngram, is_neural)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mngram\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_neural\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next_char_probabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mis_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_probability_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_valid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-bcb5bb2c1796>\u001b[0m in \u001b[0;36mget_next_char_probabilities\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mnext_char_probabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-50ecdae04fb2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x1 and 256x131)"
          ]
        }
      ],
      "source": [
        "eval_rnn_model(trainer, ds=validation_text, ds_name='valid', eval_prefixes=eval_prefixes, eval_sequences=eval_sequences, num_names=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "TMvL3KPfb-eO",
        "outputId": "15ccb6f0-9b65-4893-9f52-e0bd00121581"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Vocab' object has no attribute 'stoi'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-37dc5a2e7641>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Generate a few names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAX_NAME_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m's'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-bcb5bb2c1796>\u001b[0m in \u001b[0;36mgenerate_names\u001b[0;34m(self, k, n, prefix)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<s>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Vocab' object has no attribute 'stoi'"
          ]
        }
      ],
      "source": [
        "START = \"<s>\"   # Start-of-name token\n",
        "END = \"</s>\"    # End-of-name token\n",
        "UNK = \"<unk>\"   # token representing out of unknown (or out of vocabulary) tokens\n",
        "\n",
        "# ADD YOUR CODE HERE\n",
        "# change the directory name with your SAPname and SRno\n",
        "\n",
        "folder = 'Ashhar_Zaman_22881/rnn'\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# load the saved model\n",
        "model = torch.load(f\"{folder}/model.pt\", map_location=device)\n",
        "vocab = torch.load(f\"{folder}/vocab.pt\")\n",
        "\n",
        "# NOTE: if you are **optionally** using additional options for the trainer\n",
        "# (e.g., a training scheduler), please add them below.\n",
        "trainer = RNNTrainer(\n",
        "        model=model,\n",
        "        optimizer=None,\n",
        "        criterion=None,\n",
        "        train_dataloader=None,\n",
        "        valid_dataloader=None,\n",
        "        epochs=None,\n",
        "        use_cuda=USE_CUDA,\n",
        "        model_dir=None,\n",
        "        vocab=vocab)\n",
        "\n",
        "# Generate a few names\n",
        "names = trainer.generate_names(k=5, n=MAX_NAME_LENGTH, prefix=['a','a','s','h'])\n",
        "print(\", \".join(names))\n",
        "\n",
        "# you may use this block to test if your model and vocab load properly,\n",
        "# and that your functions are able to generate sentences, calculate perplexity etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoPkwUKs3_vy"
      },
      "outputs": [],
      "source": [
        "# Release models we don't need any more.\n",
        "del trainer\n",
        "del model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
